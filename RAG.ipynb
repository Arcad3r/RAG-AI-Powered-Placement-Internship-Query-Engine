{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460e6594-6480-40e9-999b-0239e281f530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-local'\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6026fa8-1a3f-4f2a-867f-9a84c791ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 23, 18:53:13] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c88a75-0de8-40b2-9e0c-093c90f4ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "\n",
    "# Paths to the PDFs\n",
    "\n",
    "pdf_sections = {\n",
    "    'Placement Chronicles 2023-24.pdf': '=== Placement Chronicles ===\\n',\n",
    "    'SI Chronicles 23-24 Sem I.pdf': '=== SI Chronicles ===\\n'\n",
    "}\n",
    "\n",
    "full_text = \"\"\n",
    "\n",
    "for path, section_title in pdf_sections.items():\n",
    "    full_text += section_title\n",
    "    doc = fitz.open(path)\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "\n",
    "full_document = full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2822282b-3ae0-4477-a25f-34edbd4cc7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Jul 23, 18:53:41] #> Note: Output directory .ragatouille/colbert/indexes/smile_task already exists\n",
      "\n",
      "\n",
      "[Jul 23, 18:53:45] [0] \t\t #> Encoding 390 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 13/13 [00:14<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 23, 18:54:00] [0] \t\t avg_doclen_est = 122.96410369873047 \t len(local_sample) = 390\n",
      "[Jul 23, 18:54:00] [0] \t\t Creating 2,048 partitions.\n",
      "[Jul 23, 18:54:00] [0] \t\t *Estimated* 47,956 embeddings.\n",
      "[Jul 23, 18:54:00] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/smile_task/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 20 iterations (3.3486s) to cluster 45559 items into 2048 clusters\n",
      "[0.034, 0.034, 0.031, 0.032, 0.033, 0.036, 0.032, 0.031, 0.032, 0.034, 0.033, 0.033, 0.033, 0.033, 0.034, 0.035, 0.033, 0.032, 0.032, 0.033, 0.033, 0.035, 0.032, 0.033, 0.031, 0.032, 0.035, 0.031, 0.036, 0.037, 0.034, 0.036, 0.035, 0.031, 0.033, 0.029, 0.035, 0.034, 0.033, 0.036, 0.034, 0.033, 0.032, 0.034, 0.034, 0.031, 0.033, 0.036, 0.033, 0.033, 0.033, 0.032, 0.037, 0.034, 0.032, 0.034, 0.036, 0.036, 0.04, 0.034, 0.032, 0.035, 0.033, 0.034, 0.036, 0.036, 0.036, 0.034, 0.032, 0.033, 0.033, 0.031, 0.033, 0.034, 0.033, 0.033, 0.035, 0.034, 0.035, 0.035, 0.037, 0.037, 0.033, 0.037, 0.033, 0.033, 0.034, 0.033, 0.032, 0.038, 0.036, 0.035, 0.033, 0.035, 0.032, 0.035, 0.036, 0.031, 0.033, 0.033, 0.033, 0.035, 0.033, 0.031, 0.036, 0.032, 0.032, 0.032, 0.033, 0.029, 0.034, 0.036, 0.034, 0.033, 0.032, 0.033, 0.037, 0.036, 0.033, 0.034, 0.033, 0.032, 0.034, 0.035, 0.032, 0.04, 0.035, 0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 23, 18:54:03] [0] \t\t #> Encoding 390 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.10s/it]\n",
      "1it [00:14, 14.45s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1390.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 23, 18:54:17] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jul 23, 18:54:17] #> Building the emb2pid mapping..\n",
      "[Jul 23, 18:54:18] len(emb2pid) = 47956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 160727.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 23, 18:54:18] #> Saved optimized IVF to .ragatouille/colbert/indexes/smile_task/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.ragatouille/colbert/indexes/smile_task'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG.index(\n",
    "    collection=[full_document],\n",
    "    index_name=\"smile_task\",\n",
    "    max_document_length=180,\n",
    "    split_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b028ca34-442d-425d-b49c-1066b348c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is the role of data analytics in business decision making', 'how does data analytics improve operational efficiency', 'how can data analytics be applied in predictive modeling', 'what is data analytics ?']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"\n",
    "You are a helpful assistant that generates multiple search queries based on a single input query.\n",
    "\n",
    "Given an input question, generate 3 related search queries. Then, add the original input query as the 4th (final) query.\n",
    "\n",
    "Your output should only contain the 4 queries — one per line, no explanation, no numbering.\n",
    "\n",
    "Example:\n",
    "Input: What are the effects of climate change?\n",
    "Output:\n",
    "what is the impact of climate change on weather patterns\n",
    "how does global warming affect biodiversity\n",
    "what are the long-term consequences of rising global temperatures\n",
    "What are the effects of climate change?\n",
    "\n",
    "Input: {question}\n",
    "Output:\n",
    "\"\"\".strip()\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOpenAI(model_name=\"phi-3.5:3b\",\n",
    "                 openai_api_base=\"http://127.0.0.1:1337/v1\",temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "print(generate_queries.invoke({\"question\": \"What is data analytics ?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dacaec9-6ceb-43c6-8983-4d31f8eae671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def sequential_map(fn):\n",
    "    return RunnableLambda(lambda input: [fn.invoke(x) for x in input])\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=10):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retriever = RAG.as_langchain_retriever(k=3)\n",
    "retrieval_chain_rag_fusion = generate_queries | sequential_map(retriever) | reciprocal_rank_fusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c1231c-e6b0-4d68-90c9-e58e0538ab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document 1 ---\n",
      "\n",
      "The list of companies and roles offered by them, as \n",
      "displayed by the Placement Chronicles is non-\n",
      "exhaustive.  \n",
      "24\n",
      "46\n",
      "95\n",
      "27\n",
      "19\n",
      "5\n",
      "Analytics\n",
      "05\n",
      "Accenture India\n",
      "06\n",
      "Axxela Advisory \n",
      "Services\n",
      "08\n",
      "LatentView \n",
      "Analytics\n",
      "10\n",
      "What is Data Analytics?\n",
      "The collection, organisation, and analysis of data in order to make \n",
      "informed business decisions. \n",
      "Check out some training resources provided by the Placement Unit to \n",
      "get started on your preparation for these roles -\n",
      "ug Placement Training Module for Analytics and Machine Learning by the \n",
      "Career Development Committee, Placement Unit - click hereg\n",
      "bg Basics of Data Visualisation and Machine Learning by the Career \n",
      "Development Committee, Placement Unit - click here.\n",
      "\n",
      "Score: 0.28181818181818186\n",
      "\n",
      "--- Document 2 ---\n",
      "\n",
      "The \n",
      "first question was of medium difficulty, similar to what you might find on \n",
      "LeetCode. The second question, however, posed a greater challenge as it \n",
      "was considered hard. Remember that understanding of basic courses like \n",
      "OS and DBMS, as well as C/C++ is a must.\n",
      "Round 3 - Communication Assessment\n",
      "\n",
      "In the communication assessment for the data analytics role, I  was \n",
      "evaluated on my ability to convey complex analytical findings in a clear and \n",
      "concise manner.\n",
      "Accenture India\n",
      "07\n",
      "Personal Experience\n",
      "Sources of preparation - \n",
      "\n",
      "To get ready for the analytics role interview, I practiced with sites like \n",
      "LeetCode and GeeksForGeeks. They had questions from previous \n",
      "interviews, which helped me get better at problem-solving and understand \n",
      "the kinds of challenges often asked in analytics interviews.\n",
      "\n",
      "Score: 0.25757575757575757\n",
      "\n",
      "--- Document 3 ---\n",
      "\n",
      "May these \n",
      "Chronicles inspire future batches to conquer challenges \n",
      "and secure success in their professional journeys. \n",
      "Best of luck to all!\n",
      "Foreword\n",
      "SUMMER INTERNSHIPS\n",
      "03\n",
      "Table of Contents\n",
      "04\n",
      "Analytics\n",
      "05\n",
      "Consulting\n",
      "12\n",
      "Core \n",
      "19\n",
      "Data Science\n",
      "26\n",
      "Electronics\n",
      "35\n",
      "IT\n",
      "50\n",
      "Manufacturing  \n",
      "and SCM\n",
      "106\n",
      "Quant\n",
      "115\n",
      "Analytics\n",
      "05\n",
      "DMI Finance\n",
      "06\n",
      "HDFC Bank\n",
      "08\n",
      "InfoEdge\n",
      "10\n",
      "What is Data Analytics?\n",
      "The collection, organisation, and analysis of data in order to make \n",
      "informed business decisions.\n",
      "\n",
      "Score: 0.18333333333333335\n",
      "\n",
      "--- Document 4 ---\n",
      "\n",
      "They had questions from previous \n",
      "interviews, which helped me get better at problem-solving and understand \n",
      "the kinds of challenges often asked in analytics interviews. \n",
      "Words of advice - \n",
      "\n",
      "Keep practicing with coding questions and make sure you're comfortable \n",
      "with basic CS stuff like Operating Systems (OS) and Database Management \n",
      "Systems (DBMS). If you're aiming for a placement in this role, staying sharp \n",
      "in these areas will be really helpful.\n",
      "Even though most of my classes were not exactly related to the job, the CS \n",
      "F212 - Database Systems course is really important. Don't skip learning the \n",
      "main ideas from this class, especially if you're not in A7. It'll make you better \n",
      "at answering questions about these topics, improving your chances in tests \n",
      "or interviews.\n",
      "\n",
      "Score: 0.1\n",
      "\n",
      "--- Document 5 ---\n",
      "\n",
      "If you have the time, \n",
      "diving deeper into Machine Learning, Python, and regression models could \n",
      "be helpful.\n",
      "Relevant Courses and Certification\n",
      "ºµ SQL - This is mandatory for the application process. The Placement \n",
      "Training Module for analytics was helpful and a good place to startµ\n",
      "µ Curricular Work - CS F212 (Database Systems), MATH F112 (Probability \n",
      "and Statistics), and ECON F241 (Econometric Methods) all came in \n",
      "handy over the course of the processµ\n",
      "¨µ I used GeeksforGeeks for their interview questions, as well as Ankit \n",
      "Bansal’s playlist for SQL.\n",
      "\n",
      "Score: 0.1\n",
      "\n",
      "--- Document 6 ---\n",
      "\n",
      "The collection, organisation, and analysis of data in order to make \n",
      "informed business decisions. \n",
      "Check out some training resources provided by the Placement Unit to \n",
      "get started on your preparation for these roles -m\n",
      "WV Placement Training Module for Analytics and Machine Learning by the \n",
      "Career Development Committee, Placement Unit - click hereV\n",
      "sV Basics of Data Visualisation and Machine Learning by the Career \n",
      "Development Committee, Placement Unit - click here.\n",
      "\n",
      "Score: 0.09090909090909091\n",
      "\n",
      "--- Document 7 ---\n",
      "\n",
      "So, if this is an offer you would \n",
      "like to pursue, you could certainly try obtaining some internship experience \n",
      "either off-campus or via PS-1 in data analytics.\n",
      "\n",
      "Additionally, be sure to stay very comfortable with Excel and SQL, especially \n",
      "if you aren’t from CS, as that only increases your likelihood of being asked \n",
      "questions to test your proficiency in them.\n",
      "While not a lot of my coursework was very relevant to the role, the CS F212 - \n",
      "Database Systems course is incredibly important. Do not miss out on \n",
      "learning the core concepts from this course if you are not in A7 yourself, as \n",
      "that only increases your likelihood of being asked questions pertaining to \n",
      "these topics.\n",
      "Relevant Courses or Certifications\n",
      "Round 3 - HR Interview\n",
      "\n",
      "The questions asked in this round were quite generic.\n",
      "\n",
      "Score: 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\":\"What is data analytics ?\"})\n",
    "for i, (doc, score) in enumerate(docs, 1):\n",
    "    print(f\"\\n--- Document {i} ---\\n\")\n",
    "    print(doc.page_content.strip())\n",
    "    print(f\"\\nScore: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d36700eb-98c9-4cfa-96d7-7889d931d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"phi-3.5:3b\",\n",
    "                 openai_api_base=\"http://127.0.0.1:1337/v1\",temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "428bb7f6-5233-40da-adac-663a3d7f3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/opt/anaconda3/envs/rag-env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      " The CG Cutoff for InfoEdge India Limited is 6.5+. This information is derived from the context where it mentions \"Branches open to - All\\nCG Cutoff - 6.5+\".\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the CG Cutoff for InfoEdge India Limited ? \" \n",
    "print(\"OUTPUT:\\n\\n\",final_rag_chain.invoke({\"question\": question}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48070f01-115f-493c-af80-dda28e7578a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
